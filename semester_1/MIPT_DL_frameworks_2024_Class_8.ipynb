{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\" width=\"100%\">\n",
        "    <img width=\"66%\" src=\"https://raw.githubusercontent.com/linukc/master_dlcourse/main/images/logo.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "dNcy6LVsSkgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с лидарными данными"
      ],
      "metadata": {
        "id": "vvASfXKS0csv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/mit-han-lab/torchsparse"
      ],
      "metadata": {
        "id": "TUbemtUZ24Sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse tensor (SparseTensor) is the main data structure for point cloud, which has two data fields:\n",
        "1. Coordinates (coords): a 2D integer tensor with a shape of N x 4, where the last dimensions correspond to quantized x, y, z coordinates, and the first dimension denotes the batch index\n",
        "2. Features (feats): a 2D tensor with a shape of N x C, where C is the number of feature channels."
      ],
      "metadata": {
        "id": "f2uuNTWC274Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вокселизация"
      ],
      "metadata": {
        "id": "pvESJMrA3Jbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most existing datasets provide raw point cloud data with float coordinates. We can use sparse_quantize (provided in torchsparse.utils.quantize) to voxelize x, y, z coordinates and remove duplicates:"
      ],
      "metadata": {
        "id": "1LkgxuBT3MdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import repeat\n",
        "from typing import List, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "V_hSKB_W4AbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ravel_hash(x: np.ndarray) -> np.ndarray:\n",
        "    assert x.ndim == 2, x.shape\n",
        "\n",
        "    x = x - np.min(x, axis=0)\n",
        "    x = x.astype(np.uint64, copy=False)\n",
        "    xmax = np.max(x, axis=0).astype(np.uint64) + 1\n",
        "\n",
        "    h = np.zeros(x.shape[0], dtype=np.uint64)\n",
        "    for k in range(x.shape[1] - 1):\n",
        "        h += x[:, k]\n",
        "        h *= xmax[k + 1]\n",
        "    h += x[:, -1]\n",
        "    return h\n",
        "\n",
        "def sparse_quantize(\n",
        "    coords,\n",
        "    voxel_size: Union[float, Tuple[float, ...]] = 1,\n",
        "    *,\n",
        "    return_index: bool = False,\n",
        "    return_inverse: bool = False\n",
        ") -> List[np.ndarray]:\n",
        "    if isinstance(voxel_size, (float, int)):\n",
        "        voxel_size = tuple(repeat(voxel_size, 3))\n",
        "    assert isinstance(voxel_size, tuple) and len(voxel_size) == 3\n",
        "\n",
        "    voxel_size = np.array(voxel_size)\n",
        "    coords = np.floor(coords / voxel_size).astype(np.int32)\n",
        "\n",
        "    _, indices, inverse_indices = np.unique(\n",
        "        ravel_hash(coords), return_index=True, return_inverse=True\n",
        "    )\n",
        "    coords = coords[indices]\n",
        "\n",
        "    outputs = [coords]\n",
        "    if return_index:\n",
        "        outputs += [indices]\n",
        "    if return_inverse:\n",
        "        outputs += [inverse_indices]\n",
        "    return outputs[0] if len(outputs) == 1 else outputs"
      ],
      "metadata": {
        "id": "gz87pkJq33KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.random.uniform(0, 10, size=(5, 4))\n",
        "labels = np.random.choice(10, size=5)\n",
        "\n",
        "coords, feats = inputs[:, :3], inputs\n",
        "coords -= np.min(coords, axis=0, keepdims=True)\n",
        "print(coords)\n",
        "coords, indices = sparse_quantize(coords, 1, return_index=True)\n",
        "\n",
        "coords = torch.tensor(coords, dtype=torch.int)\n",
        "feats = torch.tensor(feats[indices], dtype=torch.float)\n",
        "labels = torch.tensor(labels[indices], dtype=torch.long)\n",
        "print(coords[indices])\n",
        "\n",
        "# input = SparseTensor(coords=coords, feats=feats)\n",
        "# label = SparseTensor(coords=coords, feats=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdCeHer24k0v",
        "outputId": "6283d5cd-d0f9-44e8-9b62-44e0d252ebc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.41343857 5.03060873 2.07619563]\n",
            " [3.74821937 0.         2.6785079 ]\n",
            " [4.61045836 1.06148384 0.        ]\n",
            " [0.         2.53634713 3.90865346]\n",
            " [8.872584   6.9725617  3.07562978]]\n",
            "tensor([[5, 5, 2],\n",
            "        [3, 0, 2],\n",
            "        [4, 1, 0],\n",
            "        [0, 2, 3],\n",
            "        [8, 6, 3]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/mit-han-lab/torchsparse/blob/462dea4a701f87a7545afb3616bf2cf53dd404f3/torchsparse/utils/collate.py#L11"
      ],
      "metadata": {
        "id": "PXkPLfhB7oQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch3d"
      ],
      "metadata": {
        "id": "hnXJaZvl_OFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit a mesh via rendering https://pytorch3d.org/tutorials/fit_textured_mesh"
      ],
      "metadata": {
        "id": "gCargXMFEL7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camera position optimization using differentiable rendering https://pytorch3d.org/tutorials/camera_position_optimization_with_differentiable_rendering"
      ],
      "metadata": {
        "id": "zk0_qOgSEPVf"
      }
    }
  ]
}